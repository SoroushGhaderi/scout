# Scout - Docker Compose Configuration
# Project name: scout (set via COMPOSE_PROJECT_NAME or directory name)

services:
  # ClickHouse Database - Stores data for both FotMob and AIScore
  # NOTE: Table creation is handled by the Python script (setup_clickhouse.py)
  # in the scraper container, NOT by ClickHouse's automatic initialization.
  # The script automatically checks if databases exist and creates them if missing.
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: scout_clickhouse
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native client port
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
      # Removed: ./clickhouse/init:/docker-entrypoint-initdb.d
      # Table creation is now handled by Python script in scraper container
    environment:
      CLICKHOUSE_DB: fotmob
      CLICKHOUSE_USER: fotmob_user
      CLICKHOUSE_PASSWORD: fotmob_pass
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - football_network
    restart: unless-stopped

  # Scout Application
  scraper:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: scout_scraper
    volumes:
      # Data persistence
      - ../data:/app/data
      - ../logs:/app/logs
      # Configuration files
      - ../config:/app/config:ro
      # Allow scripts to be modified if needed
      - ../scripts:/app/scripts
      # Source code (for development - allows live code changes)
      - ../src:/app/src
      # ClickHouse init scripts (for table creation via Python script)
      - ../clickhouse:/app/clickhouse:ro
    environment:
      # Python settings
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      # Chrome/Selenium settings
      - HEADLESS=true
      - CHROME_BIN=/usr/bin/chromium
      - CHROMEDRIVER_PATH=/usr/bin/chromedriver
      # ClickHouse connection
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
      - CLICKHOUSE_USER=fotmob_user
      - CLICKHOUSE_PASSWORD=fotmob_pass
      - CLICKHOUSE_DB_FOTMOB=fotmob
      - CLICKHOUSE_DB_AISCORE=aiscore
      # Logging
      - LOG_LEVEL=INFO
      - LOG_DIR=/app/logs
    env_file:
      - ../.env
    depends_on:
      clickhouse:
        condition: service_healthy
    networks:
      - football_network
    # Resource limits
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '2.0'
          memory: 2G
    restart: unless-stopped
    # Override command to keep container running (for interactive use)
    # Uncomment to run a specific command:
    # command: ["python", "scripts/scrape_fotmob.py", "20251113"]
    # Or use: docker-compose run scraper <command>
    command: ["tail", "-f", "/dev/null"]  # Keep container running
    # Security: Run as non-root user (already set in Dockerfile)
    user: appuser

  # Optional: Scheduled scraping service (using cron)
  scheduler:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: scout_scheduler
    volumes:
      - ../data:/app/data
      - ../logs:/app/logs
      - ../config:/app/config:ro
      - ../scripts:/app/scripts
      - ../crontab:/etc/cron.d/scraper-cron:ro
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app
      - HEADLESS=true
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=8123
      - CLICKHOUSE_USER=fotmob_user
      - CLICKHOUSE_PASSWORD=fotmob_pass
    env_file:
      - ../.env
    depends_on:
      clickhouse:
        condition: service_healthy
    networks:
      - football_network
    # Install and run cron (uncomment to enable)
    # command: >
    #   bash -c "
    #   apt-get update &&
    #   apt-get install -y cron &&
    #   chmod 0644 /etc/cron.d/scraper-cron &&
    #   crontab /etc/cron.d/scraper-cron &&
    #   cron -f
    #   "
    restart: unless-stopped
    profiles:
      - scheduler  # Only start with: docker-compose --profile scheduler up

volumes:
  clickhouse_data:
    driver: local
  clickhouse_logs:
    driver: local

networks:
  football_network:
    driver: bridge
